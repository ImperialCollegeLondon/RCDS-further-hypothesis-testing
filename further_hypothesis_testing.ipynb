{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select this cell and type Ctrl-Enter to execute the code below.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, you will apply a number of commonly encountered parametric and non-parametric tests to answer a variety of research questions about an example data set.\n",
    "\n",
    "We begin with a brief exploration of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `stars.csv` contains a dataset of 240 stars, with five variables for each star:\n",
    "\n",
    "|variable | description|\n",
    "|:---|:---|\n",
    "|temperature | the surface temperature (K)|\n",
    "|luminosity | luminosity relative to sun|\n",
    "|radius | radius relative to sun|\n",
    "|spectral_class | the spectral class of each star (O,B,A,F,G,K or M)|\n",
    "|type | as defined below|\n",
    "\n",
    "\n",
    "The luminosity and radius of each star is calculated relative to that of the Sun:\n",
    "\n",
    "$L_{sun} = 3.83 \\times 10^{26}\\text{W}$\n",
    "\n",
    "$R_{sun} = 6.96 \\times 10^8\\text{m}$\n",
    "\n",
    "\n",
    "The stars are classified into 6 types:\n",
    "\n",
    "code | type\n",
    ":---|:---\n",
    "0 |Brown Dwarf\n",
    "1 |Red Dwarf\n",
    "2 |White Dwarf\n",
    "3 |Main Sequence\n",
    "4 |Supergiant\n",
    "5 |Hypergiant\n",
    "\n",
    "The dataset contains 40 examples of each type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data using the `pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"stars.csv\")\n",
    "type_key = ['Brown Dwarf', 'Red Dwarf', 'White Dwarf', 'Main Sequence', 'Supergiant','Hypergiant']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using histogram plots from `matplotlib` to visualise distributions of these variables.\n",
    "\n",
    "For example, execute the following to see an overall histogram of luminosity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.luminosity\n",
    "xlab = 'luminosity'\n",
    "ylab = 'freq'\n",
    "\n",
    "bins = np.linspace(sample.min(), sample.max())\n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "plt.hist(sample, bins, alpha=0.5, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, more usefully, on a log scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.luminosity.apply(np.log)\n",
    "xlab = 'log(luminosity)'\n",
    "ylab = 'freq'\n",
    "\n",
    "bins = np.linspace(sample.min(), sample.max())\n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "plt.hist(sample, bins, alpha=0.5, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the data by another variable to compare different groups of stars. \n",
    "\n",
    "For example, the following shows log(luminosity), grouped by type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.luminosity.apply(np.log)\n",
    "grouped = sample.groupby(data.type)\n",
    "xlab = 'log(luminosity)'\n",
    "ylab = 'freq'\n",
    "\n",
    "bins = np.linspace(sample.min(), sample.max())\n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "grouped.apply(lambda x: plt.hist(x, bins, alpha=0.5, color = 'C' + str(x.name), label=type_key[x.name]))\n",
    "ax.legend(loc='upper center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Comparing means of two groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's look at only types 4 and 5 (supergiant and hypergiant). These are of particular interest to your supervisor, Dr Howe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [4,5]\n",
    "\n",
    "sample = data.luminosity.apply(np.log)\n",
    "grouped = sample.groupby(data.type)\n",
    "\n",
    "xlab = 'log(luminosity)'\n",
    "ylab = 'freq'\n",
    "\n",
    "displayed = pd.concat([grouped.get_group(t) for t in types])\n",
    "bins = np.linspace(displayed.min(), displayed.max(), 20)\n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "\n",
    "plt.hist(grouped.get_group(types[0]), bins, alpha=0.5, label=type_key[types[0]], color='C' + str(types[0]))\n",
    "plt.hist(grouped.get_group(types[1]), bins, alpha=0.5, label=type_key[types[1]], color='C' + str(types[1]))\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr Howe has noticed that supergiants and hypergiants seem to have very similar luminosity distributions. She asks you to check whether they have the same mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: do types 4 and 5 have the same mean luminosity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample means of log(luminosity) are easy to obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type4 = data[data.type == 4].luminosity.apply(np.log)\n",
    "type5 = data[data.type == 5].luminosity.apply(np.log)\n",
    "\n",
    "mean4 = type4.mean()\n",
    "mean5 = type5.mean()\n",
    "\n",
    "print('Type 4:', mean4)\n",
    "print('Type 5:', mean5)\n",
    "print('difference:', mean4 - mean5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are certainly very similar, but is the difference between them statistically significant?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram, both distributions of log(luminosity) seem approximately symmetrical and with a rough bell-curve, so for now we will assume that they are normally distributed. (We will look later at how to test for normality.)\n",
    "\n",
    "We can therefore choose a **parametric test** for the difference between two means. This means that the test uses a defined probability distribution (e.g. the normal distribution) as a model for the process that generates the data.\n",
    "\n",
    "<br>\n",
    "\n",
    "In general, if the assumptions of a parametric test are satisfied then it will provide more **statistical power** than a non-parametric alternative. Statistical power is defined as the probability that the test *correctly rejects the null hypothesis when it is false*, also known as its *sensitivity* or *true positive rate*.\n",
    "\n",
    "Different parametric test make different **assumptions** about the data, so it is important to think carefully about whether these are satisfied before deciding on a particular test.\n",
    "\n",
    "\n",
    "In this example, a [*t-test*](https://en.wikipedia.org/wiki/Student%27s_t-test) is appropriate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-test for 2 independent groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing two samples (1 and 2), we will refer to their sizes as $n_1$ and $n_2$, their sample means as $\\bar{x}_1$ and $\\bar{x}_2$ and their sample standard deviations as $s_1$ and $s_2$.\n",
    "\n",
    "Recall that \n",
    "\n",
    "$$\\bar{x} = \\frac{\\sum_{i=1}^n x_i}{n}$$\n",
    "\n",
    "is the *sample mean*\n",
    "\n",
    "and \n",
    "\n",
    "$$s^2 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}$$\n",
    "\n",
    "is the *unbiased sample variance*.\n",
    "\n",
    "<br>\n",
    "\n",
    "For our example, we need a two-tailed test:\n",
    "\n",
    "$H_0$: The two samples come from the same distribution with mean $\\mu = \\mu_1 = \\mu_2$.\n",
    "\n",
    "$H_1$: The samples come from two different distributions, with means $\\mu_1 \\ne \\mu_2$.\n",
    "\n",
    "<br>\n",
    "\n",
    "The test statistic is given by\n",
    "\n",
    "$$t = \\frac{\\bar {x}_1 - \\bar{x}_2}{s_p \\cdot \\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}}$$,\n",
    "\n",
    "where \n",
    "\n",
    "$$s_p^2 = \\frac{\\left(n_1-1\\right)s_1^2 + \\left(n_2-1\\right)s_2^2}{n_1 + n_2-2}$$ \n",
    "\n",
    "is an unbiased estimator of the *pooled variance* of the two samples.\n",
    "\n",
    "<br>\n",
    "\n",
    "Under $H_0$, the test statistic $t$ follows a *Student's t-distribution* with $n_1 + n_2 - 2$ degrees of freedom.\n",
    "\n",
    "We use this distribution to calculate a p-value for the observed value of the test statistic, $t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions\n",
    "\n",
    "- The means of the two samples follow normal distributions. This is true if the samples themselves are normal, but also true for any other distribution if $n$ is large (by the *central limit theorem*).\n",
    "- The two populations have equal variance.\n",
    "- The two samples are independent.\n",
    "\n",
    "Two-sample t-tests are robust to moderate deviations from these assumptions, but major deviations may produce misleading results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application\n",
    "\n",
    "$H_0$: $\\mu_{\\text{type4}} = \\mu_{\\text{type5}}$.\n",
    "\n",
    "$H_1$: $\\mu_{\\text{type4}} \\ne \\mu_{\\text{type5}}$.\n",
    "\n",
    "Let's set a significance level $\\alpha=0.05$\n",
    "\n",
    "Using a statistical library such as `scipy.stats`, we just supply the data for each sample and the test function deals with the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(type4, type5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise this result on the t-distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_obs = stats.ttest_ind(type4, type5).statistic\n",
    "df = len(type4) + len(type5) - 1\n",
    "print(\"degrees of freedom:\", df)\n",
    "\n",
    "tmin = -4\n",
    "tmax = 4\n",
    "\n",
    "t = stats.t(df)\n",
    "x = np.linspace(tmin,tmax,100)\n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"pdf\")\n",
    "plt.plot(x, t.pdf(x), color='gray')\n",
    "\n",
    "# the area of the shaded region is the two-tailed p-value\n",
    "lower_tail = np.linspace(tmin,-t_obs,100)\n",
    "upper_tail = np.linspace(t_obs,tmax,100)\n",
    "plt.fill_between(lower_tail,t.pdf(lower_tail),color='lightgrey')\n",
    "plt.fill_between(upper_tail,t.pdf(upper_tail),color='lightgrey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test p-value is greater than than $\\alpha$, so we accept the null hypothesis that the means are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other types of t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-tailed t-test\n",
    "\n",
    "In the example above, we used a *two-tailed test* (because $H_1:\\mu_1 \\ne \\mu_2$ was symmetrical). \n",
    "\n",
    "For a *one-tailed test*, we need to halve the two-sided p-value, e.g. \n",
    "\n",
    "$H_1:\\mu_{\\text{type4}}>\\mu_{\\text{type5}}$ would give us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"pdf\")\n",
    "plt.plot(x, t.pdf(x), color='gray')\n",
    "\n",
    "# the area of the shaded region is the one-tailed p-value for H1: mu_1 > mu_2\n",
    "upper_tail = np.linspace(t_obs,tmax,100)\n",
    "plt.fill_between(upper_tail,t.pdf(upper_tail),color='lightgrey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_2tailed = stats.ttest_ind(type4, type5).pvalue\n",
    "p_1tailed = p_2tailed/2\n",
    "print('1-tailed p-value:', p_1tailed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the complementary hypothesis (i.e. $H_1:\\mu_1<\\mu_2$), we would need to use `1 - p_1tailed`, e.g. \n",
    "\n",
    "$H_1:\\mu_{\\text{type4}}<\\mu_{\\text{type5}}$ would give us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"pdf\")\n",
    "plt.plot(x, t.pdf(x), color='gray')\n",
    "\n",
    "# the area of the shaded region is the one-tailed p-value for H1: mu_1 < mu_2\n",
    "lower_tail = np.linspace(tmin,t_obs,100)\n",
    "plt.fill_between(lower_tail,t.pdf(lower_tail),color='lightgrey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_2tailed = stats.ttest_ind(type5, type4).pvalue\n",
    "p_1tailed = p_2tailed/2\n",
    "print('1-tailed p-value:', 1 - p_1tailed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Paired two-sample t-test\n",
    "\n",
    "Sometimes we have two samples with paired observations (for example, luminosity of the same set of stars, as measured on two different dates). This situation requires testing whether the *mean of the differences* between pairs is zero, which is called a [*paired two-sample t-test*](https://en.wikipedia.org/wiki/Student%27s_t-test#Dependent_t-test_for_paired_samples).\n",
    "\n",
    "#### Welch's t-test\n",
    "\n",
    "If the sample sizes in the two groups being compared are equal, Student's original t-test is highly robust to the presence of unequal variances. [*Welch's t-test*](https://en.wikipedia.org/wiki/Welch%27s_t-test) is an alternative that is insensitive to equality of the variances, regardless of whether the sample sizes are similar.\n",
    "\n",
    "#### One-sample t-test\n",
    "\n",
    "For cases where we want to compare a sample against a theoretical mean, we can use the [*one-sample t-test*](https://en.wikipedia.org/wiki/Student%27s_t-test#One-sample_t-test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatives to the t-test\n",
    "\n",
    "#### Mann-Whitney U-test\n",
    "\n",
    "For non-normal samples where $n$ is small, the assumptions of the t-test break down. However, we can use a *non-parametric test* to compare two samples, whatever the shape of their distributions.\n",
    "\n",
    "The [*Mann-Whitney U-test*](https://en.wikipedia.org/wiki/Mann–Whitney_U_test) (aka Wilcoxon rank-sum test) is one such test. The null hypothesis for this test is that a randomly selected value from sample 1 is equally likely to be less than or greater than a randomly selected value from sample 2. If the distributions are sufficiently different, the resulting p-value will be small and we will reject this null hypothesis. Note that the U-test does not compare the sample means directly.\n",
    "\n",
    "\n",
    "#### Wilcoxon signed-rank test\n",
    "\n",
    "The [*Wilcoxon signed-rank test*](https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test) is is the paired-sample version of the Mann-Whitney U-test.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Comparing variances of two groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test only compares the *means* of the two groups. \n",
    "Next, Dr Howe would like you to check their *variances*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: do types 4 and 5 have the same variance in log(luminosity)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Q plot\n",
    "\n",
    "The [*quantile-quantile plot*](https://en.wikipedia.org/wiki/Q–Q_plot) (Q-Q plot) is a simple, graphical method to check whether two sets of observations appear to come from the same distribution, or to compare one set of data to a theoretical distribution.\n",
    "\n",
    "It is made by plotting the quantiles (i.e. percentiles) of the two distributions against each other.\n",
    "\n",
    "If the variances are the same, the Q-Q plot will approximate a straight line with gradient 1.\n",
    "\n",
    "We can find the percentiles for our sample directly with `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,101)\n",
    "t4q = np.array(type4.quantile(x))\n",
    "t5q = np.array(type5.quantile(x))\n",
    "\n",
    "f = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ymin=11\n",
    "ymax=14\n",
    "\n",
    "ax = plt.subplot(121)\n",
    "ax.set_xlabel('quantile')\n",
    "ax.set_ylabel('type 4')\n",
    "ax.set_ylim([ymin,ymax])\n",
    "plt.scatter(x,t4q,color='C4')\n",
    "\n",
    "ax = plt.subplot(122)\n",
    "ax.set_xlabel('quantile')\n",
    "ax.set_ylabel('type 5')\n",
    "ax.set_ylim([ymin,ymax])\n",
    "plt.scatter(x,t5q,color='C5')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting type 5 against type 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlab = 'type 4'\n",
    "ylab = 'type 5'\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "\n",
    "plt.scatter(t4q, t5q, color='gray')\n",
    "\n",
    "# the line with gradient 1, passing through Q50:\n",
    "m = 1\n",
    "c = t5q[50] - t4q[50] * m\n",
    "plt.plot(t4q, m * t4q + c, color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a pretty good fit, but we can do an [*F-test*](https://en.wikipedia.org/wiki/F-test_of_equality_of_variances) to be more rigorous:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-test for equality of variances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory\n",
    "\n",
    "Once again, we need a two-tailed test:\n",
    "\n",
    "$H_0$: The two populations have identical variance  $\\sigma^2 = \\sigma_1^2 = \\sigma_2^2$.\n",
    "\n",
    "$H_1$: The two populations have non-identical variances, $\\sigma_1^2 \\ne \\sigma_2^2$.\n",
    "\n",
    "The test statistic is simply the ratio of the sample variances:\n",
    "\n",
    "$$F = \\frac{s_1^2}{s_2^2}$$.\n",
    "\n",
    "Under $H_0$, $F$ follows an [*F-distribution*](https://en.wikipedia.org/wiki/F-distribution) with parameters $(n_1 - 1,n_2 - 1)$.\n",
    "\n",
    "We use this distribution to calculate a p-value for the observed value of the test statistic, $F$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumpions\n",
    "\n",
    "- The two samples both follow normal distributions.\n",
    "\n",
    "Note that the means of the two populations may differ.\n",
    "The F-test is highly sensitive to deviations from the assumption of normality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application\n",
    "\n",
    "We will set $\\alpha=0.05$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise the F-distribution corresponding to our example ($n_1 = n_2 = 40$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.1,3)\n",
    "plt.plot(x,stats.f.pdf(x,39,39), color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate the test statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstat = type4.var()/type5.var()\n",
    "print(\"F =\",fstat)\n",
    "\n",
    "plt.plot(x,stats.f.pdf(x,39,39), color='gray')\n",
    "x_region = np.linspace(0.1,fstat,100)\n",
    "plt.fill_between(x_region,stats.f.pdf(x_region,39,39),color='lightgrey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the CDF to calculate the left-tail $p$-value and double it for a two-tailed test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = stats.f.cdf(fstat,39,39) * 2\n",
    "print(\"p =\",p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $p>\\alpha$ so we accept the null hypothesis of equal variance, at the 5% level.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Comparing means of more than two groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the course of your investigations for Dr Howe, you have noticed that the distributions of the dwarf stars' luminosities (types 0,1 and 2) are also overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [0,1,2]\n",
    "\n",
    "sample = data.luminosity.apply(np.log)\n",
    "grouped = sample.groupby(data.type)\n",
    "\n",
    "xlab = 'log(luminosity)'\n",
    "ylab = 'freq'\n",
    "\n",
    "displayed = pd.concat([grouped.get_group(t) for t in types])\n",
    "bins = np.linspace(displayed.min(), displayed.max(), 20)\n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "\n",
    "for t in types:\n",
    "    plt.hist(grouped.get_group(t), bins, alpha=0.5, label=type_key[t], color='C' + str(t))\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: do types 0, 1 and 2 have the same mean luminosity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test can only compare the means of two samples (or one sample with a theoretical mean). \n",
    "\n",
    "To move beyond two samples, we need to use a different method called [*analysis of variance*](https://en.wikipedia.org/wiki/Analysis_of_variance) (ANOVA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-way ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: All of the groups have identical means:  $\\mu = \\mu_1 = \\mu_2 = \\mu_3$.\n",
    "\n",
    "$H_1$: Not all of the group means are identical.\n",
    "\n",
    "The one-way (also known as single-factor) ANOVA uses the F-test to compare the within-group and between-group variation:\n",
    "\n",
    "$$F = \\frac{\\text{between-group variation}}{\\text{within-group variation}}$$\n",
    "\n",
    "Under $H_0$, $F$ follows an F-distribution with parameters $(g-1,n_T-1)$, where $g$ is the number of groups (here, 3 types of star), and $n_T$ is the total number of observations.\n",
    "\n",
    "Once again, the F-distribution provides a p-value associated with the calculated value of $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions\n",
    "\n",
    "- Observations are independent.\n",
    "- Populations are normally distributed.\n",
    "- Variances of the populations are equal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application\n",
    "\n",
    "We will set $\\alpha=0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f_oneway(grouped.get_group(0),grouped.get_group(1),grouped.get_group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have $p<\\alpha$, so we reject $H_0$: the three groups do not appear to have the same mean luminosity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other types of ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA is an important element of statistical analysis when we are interested in comparing the effects of different treatments. \n",
    "\n",
    "The underlying statistical model changes, depending on the expected relationship between treatment and effect (*fixed-*, *random-* or *mixed-effects*).\n",
    "\n",
    "Where multiple variables change simultaneously (for example, in patient populations), we may need to consider *multiple factors* (e.g. *two-way ANOVA*) and the *interactions* between factors.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Comparing distributions over a categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your undergraduate project student, Tunde, is looking at the distributions of spectral class (i.e. colour) for various types of star. \n",
    "\n",
    "He says that the bar charts for white dwarves (type 2) and main sequence stars (type 3) seem similar, but you are not so sure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['O','B','A','F','G','K','M']\n",
    "\n",
    "grouped = data.groupby(data.type)\n",
    "\n",
    "classes2 = grouped.get_group(2).spectral_class.value_counts()\n",
    "classes3 = grouped.get_group(3).spectral_class.value_counts()\n",
    "\n",
    "for i in labels:\n",
    "    if (i not in classes2):\n",
    "        classes2[i] = 0 \n",
    "    if (i not in classes3):\n",
    "        classes3[i] = 0 \n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, [classes2[i] for i in labels], width, alpha=0.4, color = 'C2', label=type_key[2])\n",
    "rects2 = ax.bar(x + width/2, [classes3[i] for i in labels], width, alpha=0.8, color = 'C3', label=type_key[3])\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: do types 2 and 3 share the same distribution of spectral class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test differences in distributions over a *categorical variable* like spectral class, we can use [*Pearson's chi-squared test*](https://en.wikipedia.org/wiki/Chi-squared_test):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared test for statistical independence\n",
    "\n",
    "#### Theory\n",
    "\n",
    "$H_0$: Probability distribution for the categorical variable (e.g. spectral class) is independent of group (e.g. star type).\n",
    "\n",
    "$H_1$: Probability distribution depends on group.\n",
    "\n",
    "We need to find out whether the differences in observed frequencies between the two groups are small enough to have arisen by chance. We do this by constructing a [*contingency table*](https://en.wikipedia.org/wiki/Contingency_table) showing the observed frequency of each outcome for each of the two groups, and comparing to the *expected frequencies* under $H_0$.\n",
    "\n",
    "\n",
    "The test statistic is\n",
    "\n",
    "$$X^2 = \\sum^k_{i=1}{\\frac{(x_i-m_i)^2}{m_i}}$$,\n",
    "\n",
    "where $k$ is the number of cells in the table and $x_i$ and $m_i$ are the observed and expected frequencies for each cell.\n",
    "\n",
    "Under $H_0$, $X^2$ follows a [$\\chi^2$ distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution), which is parametrised by the number of degrees of freedom. A contingency table of size $a \\times b$ has $(a-1)(b-1)$ degrees of freedom, i.e. the number of independent counts when row and column sums are held fixed.\n",
    "\n",
    "#### Assumptions\n",
    "\n",
    "- Sampling is random\n",
    "- Each sample is independent of the others\n",
    "- Expected frequency for each cell must be sufficiently large\n",
    "\n",
    "The approximation to the $\\chi^2$ distribution breaks down if expected frequencies are too low. It will normally be acceptable so long as no more than 20% of the events have expected frequencies below 5. Where there is only 1 degree of freedom (i.e. a 2 $\\times$ 2 table), the approximation is not reliable if expected frequencies fall below 10. \n",
    "\n",
    "\n",
    "#### Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set $\\alpha=0.05$.\n",
    "\n",
    "We begin by making a contingency table for the observed spectral classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBSERVED\n",
    "\n",
    "types = [2,3]\n",
    "subset = pd.concat([grouped.get_group(t) for t in types])\n",
    "\n",
    "obs = pd.crosstab(subset.type,subset.spectral_class,margins=True,margins_name=\"total\")\n",
    "print(\"OBSERVED:\")\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the row and column totals, we can calculate the *expected* frequencies under $H_0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPECTED\n",
    "\n",
    "exp = pd.DataFrame(stats.contingency.expected_freq(obs))\n",
    "exp.columns = obs.columns\n",
    "exp = exp.rename(index={0:2,1:3,2:\"total\"})\n",
    "exp = exp.rename_axis(columns=obs.axes[1].name,index=obs.axes[0].name)\n",
    "print(\"EXPECTED:\")\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected values for classes K and O are too small. We can combine the last three columns to get all of the expected values over 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBSERVED (combining columns)\n",
    "\n",
    "new_obs = obs[['A','B']][:-1]\n",
    "new_obs['others'] = obs[['F','K','O']][:-1].sum(axis=1)\n",
    "print(\"OBSERVED:\")\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPECTED (combining columns)\n",
    "\n",
    "new_exp = pd.DataFrame(stats.contingency.expected_freq(new_obs))\n",
    "new_exp.columns = new_obs.columns\n",
    "new_exp = new_exp.rename(index={0:2,1:3})\n",
    "new_exp = new_exp.rename_axis(columns=new_obs.axes[1].name,index=new_obs.axes[0].name)\n",
    "print(\"EXPECTED:\")\n",
    "new_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `scipy.stats`, he most convenient form of the chi-squared test for a contingency table is `chi2_contingency`, which just takes the table of observations as input and calculates the expected values and degrees of freedom accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = stats.chi2_contingency(new_obs)[1]\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the chi-squared test, $p<\\alpha$, so there is enough evidence to reject $H_0$:\n",
    "it appears that white dwarves and main sequence stars follow different distributions for spectral class.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Testing for normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Professor Xu thinks that the current system for classifying stars can be improved. In particular, she thinks that log(temperature) should be normally distributed for each star type. \n",
    "\n",
    "She has asked you to find out whether this is true under the current classification system, and if not, which types should be revised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: for which star types is log(temperature) normally distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Q plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory\n",
    "\n",
    "We can use a Q-Q plot to investigate whether each sample resembles a normal distribution.\n",
    "\n",
    "If we set\n",
    "\n",
    "$x =$ the theoretical quantiles from the standard normal ($Z$) distribution, and\n",
    "\n",
    "$y =$ the quantiles from the sample,\n",
    "\n",
    "the Q-Q plot will be close to a straight line for samples that are approximately normally distributed.\n",
    "\n",
    "Although this is not a rigorous statistical method, it can be enough to suggest whether a normal approximation is likely to be valid for a particular data set, or to diagnose [*skewness*](https://en.wikipedia.org/wiki/Skewness) and/or [*kurtosis*](https://en.wikipedia.org/wiki/Kurtosis) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plots(sample, col='gray', lab=None, mu=None, sigma=None):\n",
    "    \n",
    "    if(mu):\n",
    "        n = len(sample)\n",
    "        norm_fit = stats.norm(loc=mu, scale=sigma)\n",
    "  \n",
    "    f = plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # histogram\n",
    "    ax = plt.subplot(121)\n",
    "    \n",
    "    nbins = 20\n",
    "    smin = sample.min()\n",
    "    smax = sample.max()\n",
    "    binwidth = (smax - smin)/nbins\n",
    "    bins = np.linspace(sample.min(), sample.max(), nbins)\n",
    "    \n",
    "    xlab = 'observed'\n",
    "    ylab = 'freq'\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    \n",
    "    ax.hist(sample, bins, alpha=0.5, color=col, label=lab)\n",
    "    \n",
    "    if(mu):\n",
    "        plt.plot(bins, n * binwidth * norm_fit.pdf(bins), color='black')\n",
    "    \n",
    "    if(lab):\n",
    "        ax.legend(loc='upper left')\n",
    "    \n",
    "    # Q-Q plot\n",
    "    \n",
    "    ax = plt.subplot(122)\n",
    "    \n",
    "    x = np.linspace(0,1,100)\n",
    "    normal_q = stats.norm.ppf(x)\n",
    "    sample_q = np.array(np.quantile(sample,x))\n",
    "    \n",
    "    xlab = 'standard normal'\n",
    "    ylab = 'observed'\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    \n",
    "    # the plot itself:\n",
    "    ax.scatter(normal_q,sample_q, color=col, label=lab)\n",
    "    \n",
    "    # the line passing through Q25 and Q75:\n",
    "    m = (sample_q[75] - sample_q[25])/(normal_q[75] - normal_q[25])\n",
    "    c = sample_q[25] - normal_q[25] * m\n",
    "    ax.plot(normal_q, m * normal_q + c, color='black')\n",
    "    \n",
    "    if(lab):\n",
    "        ax.legend(loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normally distributed data\n",
    "sample = stats.norm.rvs(loc=10,scale=2,size=100)\n",
    "\n",
    "### positively skewed data (e.g. lognormal)\n",
    "#sample = stats.lognorm.rvs(0.5,size=100)\n",
    "\n",
    "### negatively skewed data (e.g. constant - lognormal)\n",
    "#sample = 20 - stats.lognorm.rvs(0.5,size=100)\n",
    "\n",
    "### leptokurtic (heavy-tailed) data (e.g. Student's t-distribution with df=2)\n",
    "#sample = stats.t.rvs(2,loc=200,size=100)\n",
    "\n",
    "### platykurtic (thin-tailed) data (e.g. uniform distribution)\n",
    "#sample = stats.uniform.rvs(loc=10,scale=20,size=100)\n",
    "\n",
    "do_plots(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be a useful way to identify the data points that are responsible for any deviations from normality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application\n",
    "\n",
    "Run the code below to see the histograms and Q-Q plots for log(temperature) for each star type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set the star type to test\n",
    "t = 0\n",
    "\n",
    "sample = data[data.type == t].temperature.apply(np.log)\n",
    "col= 'C' + str(t)\n",
    "lab= type_key[t]\n",
    "\n",
    "mu = sample.mean()\n",
    "sigma = sample.std()\n",
    "\n",
    "do_plots(sample,col,lab,mu,sigma)\n",
    "print(type_key[t])\n",
    "print('mean:', mu, '   SD:', sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For which of the star types does log(temperature) appear approximately normal? How would you describe the other distributions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, for a more rigorous investigation of normality, we can use a statistical test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapiro-Wilk test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory\n",
    "\n",
    "The [*Shapiro–Wilk test*](https://en.wikipedia.org/wiki/Shapiro–Wilk_test) tests the null hypothesis that a sample $x_1, ..., x_n$ came from a normally distributed population.\n",
    "\n",
    "It compares statistics obtained from the observed data to the expected values of statistics sampled from the standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shapiro-Wilk test is easy to apply in scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set the star type to test\n",
    "t = 0\n",
    "\n",
    "sample = data[data.type == t].temperature.apply(np.log)\n",
    "p_value = stats.shapiro(sample)[1]\n",
    "\n",
    "print(type_key[t])\n",
    "print('p =', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Shapiro-Wilk test to each of the star types. Which of them produce p-values less than $\\alpha$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative tests for normality\n",
    "\n",
    "Many other tests for normality have been developed, including the Anderson-Darling, Cramér–von Mises and Kolmogorov-Smirnov (see below) tests. \n",
    "\n",
    "The Shapiro-Wilk test has been found to have the best statistical power for a given significance level.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Correcting for multiple hypothesis tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there is a problem with the previous analysis.\n",
    "\n",
    "Recall that the significance level, $\\alpha$, is defined as the probability of incorrectly rejecting $H_0$ when it is actually true (i.e. the probability of a Type I error).\n",
    "\n",
    "When we perform [*multiple related hypothesis tests*](https://en.wikipedia.org/wiki/Multiple_comparisons_problem), we increase the chances of producing such a Type I error.\n",
    "\n",
    "For example, if $\\alpha=0.05$ and we perform 100 tests, we *expect* to generate 5 Type I errors. This can be a serious problem when large numbers of hypothesis tests are carried out simultaneously, for example in screening thousands of genes for association with a disease.\n",
    "\n",
    "We therefore need a strategy to control the rate of Type I errors. A very simple approach is given by the [*Bonferroni correction*](https://en.wikipedia.org/wiki/Bonferroni_correction):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonferroni correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory\n",
    "\n",
    "When conducting $n$ related hypothesis tests, we reduce the significance level for each test to $\\alpha/n$.\n",
    "\n",
    "The probability of making a Type I error *over the whole set of tests* (known as the *family-wise error rate*, FWER) therefore remains at $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapiro-Wilk test for normality\\n\")\n",
    "\n",
    "p_values = []\n",
    "alpha = 0.05\n",
    "n = 6\n",
    "\n",
    "for t in range(0,n):\n",
    "    sample = data[data.type == t].temperature.apply(np.log)\n",
    "    p_values.append(stats.shapiro(sample)[1])\n",
    "\n",
    "print(\"with uncorrected alpha =\",np.format_float_scientific(alpha,3),\":\")\n",
    "for i in range(0,n):\n",
    "    result = \"\"\n",
    "    if(p_values[i] < alpha): result = \"*** REJECT H0 ***\"\n",
    "    print(i, type_key[i], \": p =\", np.format_float_scientific(p_values[i],3), result) \n",
    "\n",
    "\n",
    "    \n",
    "print(\"\\nwith Bonferroni correction, alpha/n =\",np.format_float_scientific(alpha/n,3),\":\")\n",
    "for i in range(0,n):\n",
    "    result = \"\"\n",
    "    if(p_values[i] < alpha/n): result = \"*** REJECT H0 ***\"\n",
    "    print(i, type_key[i], \": p =\", np.format_float_scientific(p_values[i],3), result) \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After correcting for multiple hypothesis testing, the red dwarf p-value is not significant.\n",
    "\n",
    "We should report to Professor Xu that log(temperature) is not normally distributed for the brown dwarf, supergiant and hypergiant types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative methods for multiple testing correction\n",
    "\n",
    "The Bonferroni correction is simple to apply, but it may be too conservative when there is a very large numbers of tests, or when the tests are not independent (for example, genes are often related to other genes so are likely to share properties).\n",
    "\n",
    "The [*Benjamini-Hochberg procedure*](https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini–Hochberg_procedure) is an alternative approach. Instead of controlling the FWER, this method controls the *proportion of the positive tests that are incorrect*, i.e. the proportion of rejected $H_0$'s that are Type I errors. This is known as the *false-discovery rate*, FDR.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your colleague Althea is not a fan of Prof. Xu's temperature scheme. She has her own ideas about how the star classification should be revised.\n",
    "\n",
    "According to Althea's new theory of stellar evolution, there are two subtypes of hypergiant star, with very different temperature distributions. \n",
    "\n",
    "She says that our galaxy has approximately equal numbers of each subtype. \n",
    "\n",
    "If this theory is true, hypergiant temperatures should be distributed according to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(3000K \\leq \\text{T} \\lt 4000K) = 0.5 \\\\\n",
    "P(4000K \\leq \\text{T} \\lt 40000K) = 0.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with uniform temperature distributions within each of the two subtypes.\n",
    "\n",
    "Althea asks you to check whether her theory agrees with your data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: do hypergiants in the observed data set fit Althea's theory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pdf associated with the theory is piecewise uniform. We can construct this as a bespoke continuous probability distribution with `scipy.stats`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def althea_F(x):\n",
    "    if(x<3000):\n",
    "        return 0\n",
    "    elif(x<4000):\n",
    "        return 0.5*(x-3000)/(4000-3000)\n",
    "    elif(x<40000):\n",
    "        return 0.5 + 0.5*(x-4000)/(40000-4000)\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "class althea(stats.rv_continuous):\n",
    "    \"Althea's distribution\"\n",
    "    def _cdf(self, x):\n",
    "        return np.vectorize(althea_F)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = althea()\n",
    "x = np.arange(0,50000,100)\n",
    "\n",
    "y = []\n",
    "for z in x:\n",
    "    y.append(al.pdf(z))\n",
    "\n",
    "xlab = 'temperature'\n",
    "ylab = 'probability density'    \n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "plt.plot(x, y, color='tab:orange', label='theoretical pdf')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, the histogram for the hypergiants (type 5) does appear to have a similar shape to this pdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = data[data.type == 5].temperature\n",
    "n = len(observed)\n",
    "\n",
    "xlab = 'temperature'\n",
    "ylab = 'freq'\n",
    "\n",
    "bins = np.linspace(0,50000)\n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "obs_hist = plt.hist(observed, bins, alpha=0.5, label='observed data')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see more clealy, we can overlay a random sample of the same size ($n$=40), drawn from the theoretical distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = al.rvs(size=n)\n",
    "\n",
    "xlab = 'temperature'\n",
    "ylab = 'freq'\n",
    "\n",
    "bins = np.linspace(0,50000)\n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "obs_hist = plt.hist(observed, bins, alpha=0.5, label='observed data')\n",
    "exp_hist = plt.hist(expected, bins, alpha=0.5, label='sampled from theoretical distribution')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we test more formally whether the observed data appear to be drawn from the theoretical distribution?\n",
    "\n",
    "Here we have a theoretical distribution *which is not directly related to any of the standard statistical distributions*, so parametric methods such as the Shapiro-Wilk test are not applicable.\n",
    "\n",
    "However, we can still perform a *non-parametric* goodness-of-fit test, by comparing the theoretical cdf with the empirical one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = np.histogram(observed, bins=100)\n",
    "empirical_dist = stats.rv_histogram(hist)\n",
    "\n",
    "x = np.arange(0,50000,100)\n",
    "\n",
    "y_theoretical = []\n",
    "y_empirical = []\n",
    "\n",
    "for z in x:\n",
    "    y_theoretical.append(al.cdf(z))\n",
    "    y_empirical.append(empirical_dist.cdf(z))\n",
    "\n",
    "xlab = 'temperature'\n",
    "ylab = 'cumulative probability'\n",
    "    \n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "plt.plot(x, y_empirical, label='empirical cdf')\n",
    "plt.plot(x, y_theoretical, label='theoretical cdf')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory\n",
    "\n",
    "The [*Kolmogorov-Smirnov test*](https://en.wikipedia.org/wiki/Kolmogorov–Smirnov_test) (or K-S test) examines the deviation of the empirical cdf, $F_n(x)$, from the theoretical one, $F(x)$, to assess the goodness-of-fit. The test statistic is the quantity\n",
    "\n",
    "$$\n",
    "D_n= \\sup_x |F_n(x)-F(x)|,\n",
    "$$\n",
    "\n",
    "i.e. the greatest vertical distance between the two curves.\n",
    "\n",
    "The distribution of $D_n$ under the null hypothesis $H_0: F_n(x) = F(x)$ is called the *Kolmogorov distribution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application\n",
    "\n",
    "In our example,\n",
    "\n",
    "$H_0$: $F_n(x) = F(x)$  : The observed temperature distribution of hypergiants is described by Althea's theory.\n",
    "\n",
    "$H_1$: $F_n(x) \\ne F(x)$  : The observed temperature distribution of hypergiants is not described by Althea's theory.\n",
    "\n",
    "$\\alpha = 0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphically, we can plot $D_n$ for each $x$-value in the plot above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlab = 'temperature'\n",
    "ylab = 'empirical cdf - theoretical cdf'\n",
    "\n",
    "#y_values = np.abs(np.array(y_empirical)-np.array(y_theoretical))\n",
    "y_values = np.array(y_empirical)-np.array(y_theoretical)\n",
    "    \n",
    "ax = plt.axes()\n",
    "ax.set_xlabel(xlab)\n",
    "ax.set_ylabel(ylab)\n",
    "plt.plot(x, y_values, color='black')\n",
    "plt.show()\n",
    "\n",
    "D_n = np.max(np.abs(y_values))\n",
    "print('D_n:', D_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test itself is easy in `scipy.stats`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stats.kstest(observed, al.cdf)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting $p > \\alpha$, so we accept the null hypothesis: the observed data appear to be compatible with Althea's theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other applications of the K-S test\n",
    "\n",
    "#### Goodness of fit\n",
    "\n",
    "The K-S test can be used as an alternative method for testing normality, or as a goodness-of-fit test for any other theoretical distribution. However, the standard test is only valid if the parameters (e.g. mean and variance) are *not* estimated from the data. \n",
    "\n",
    "If parameters *are* estimated from the data, we will need to use simulation to find an empirical distribution for $D_n$ under $H_0$.\n",
    "\n",
    "\n",
    "#### Two sample test\n",
    "\n",
    "The K-S test is often used to compare two samples (in the absence of a theoretical cdf) to test whether they follow the same distribution. \n",
    "\n",
    "In `scipy.stats`, this is done with the function `ks_2samp`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
